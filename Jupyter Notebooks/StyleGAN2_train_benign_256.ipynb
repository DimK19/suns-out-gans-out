{"cells":[{"cell_type":"markdown","metadata":{"id":"wzWrFN_tGV-Y"},"source":["# Set Up New Environment\n","\n","You will likely need to train for >24 hours.  Colab will disconnect you.  You must be prepared to restart training when this eventually happens.  Training is divided into ticks, every so many ticks (50 by default) your neural network is evaluated and a snapshot is saved.  When CoLab shuts down, all training after the last snapshot is lost. It might seem desirable to snapshot after each tick; however, this snapshotting process itself takes nearly an hour.  It is important to learn an optimal snapshot size for your resolution and training data.\n","\n","We will mount GDRIVE so that your snapshots are saved there.  You must also place your training images in GDRIVE."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfUhmhlivB61","executionInfo":{"status":"ok","timestamp":1653579632833,"user_tz":-180,"elapsed":20253,"user":{"displayName":"Dim K","userId":"06229829716267511115"}},"outputId":"c220bffe-d7e0-43e1-fb48-288281a791d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"X41Ll0WtYqB0"},"source":["You must also install NVIDIA StyleGAN2 ADA PyTorch.  We also need to downgrade PyTorch to a version that supports StyleGAN."]},{"cell_type":"code","source":["!pip install torch==1.8.1 torchvision==0.9.1\n","!pip install ninja"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIIDWgL-vnOJ","executionInfo":{"status":"ok","timestamp":1653579758364,"user_tz":-180,"elapsed":111142,"user":{"displayName":"Dim K","userId":"06229829716267511115"}},"outputId":"dc55dd83-a01f-4170-b8c0-aa022d63e612"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.1\n","  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n","\u001b[K     |████████████████████████████████| 804.1 MB 2.6 kB/s \n","\u001b[?25hCollecting torchvision==0.9.1\n","  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n","\u001b[K     |████████████████████████████████| 17.4 MB 808 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (4.2.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.1 torchvision-0.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: ninja\n","Successfully installed ninja-1.10.2.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"JXAgXh8uGo13"},"source":["# Convert Your Images"]},{"cell_type":"code","source":["/content/drive/My\\ Drive/Colab Notebooks/Health/"],"metadata":{"id":"Y3v9rAXmwVeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/My\\ Drive/Colab\\ Notebooks/Health/stylegan2-pytorch/stylegan2-ada-pytorch/dataset_tool.py --source /content/drive/My\\ Drive/Colab\\ Notebooks/Health/DATASET/benign_256 --dest /content/drive/My\\ Drive/Colab\\ Notebooks/Health/torch_data_benign_256"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4HCqIfDwX9N","executionInfo":{"status":"ok","timestamp":1653579797393,"user_tz":-180,"elapsed":11343,"user":{"displayName":"Dim K","userId":"06229829716267511115"}},"outputId":"c983af8a-15f2-4566-d256-d206ddfbcf07"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 437/437 [00:06<00:00, 65.08it/s] \n"]}]},{"cell_type":"markdown","metadata":{"id":"otsNELpn8_2D"},"source":["The following command can be used to clear out the newly created dataset.  If something goes wrong and you need to clean up your images and rerun the above command, you should delete your partially created dataset directory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctdqmU96BhB3"},"outputs":[],"source":["#!rm -R /content/drive/MyDrive/data/gan/dataset/circuit/*"]},{"cell_type":"markdown","metadata":{"id":"5No-bokaG5Ed"},"source":["# Perform Initial Training"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tzAdHMp7KLzz","executionInfo":{"status":"ok","timestamp":1653579867148,"user_tz":-180,"elapsed":259,"user":{"displayName":"Dim K","userId":"06229829716267511115"}}},"outputs":[],"source":["import os\n","\n","# Modify these to suit your needs\n","EXPERIMENTS = \"/content/drive/My\\ Drive/Colab\\ Notebooks/Health/torch_res_b256\"\n","DATA = \"/content/drive/My\\ Drive/Colab\\ Notebooks/Health/torch_data_benign_256\"\n","SNAP = 10"]},{"cell_type":"code","source":["# Build the command and run it\n","cmd = f\"python3 /content/drive/My\\ Drive/Colab\\ Notebooks/Health/stylegan2-pytorch/stylegan2-ada-pytorch/train.py --snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\n","!{cmd}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DU4OYi9AxhSH","outputId":"f1188550-2f15-40b2-bc5a-eaa0b64c7d04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 10,\n","  \"network_snapshot_ticks\": 10,\n","  \"metrics\": [\n","    \"fid50k_full\"\n","  ],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"/content/drive/My Drive/Colab Notebooks/Health/torch_data_benign_256\",\n","    \"use_labels\": false,\n","    \"max_size\": 437,\n","    \"xflip\": false,\n","    \"resolution\": 256\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"synthesis_kwargs\": {\n","      \"channel_base\": 16384,\n","      \"channel_max\": 512,\n","      \"num_fp16_res\": 4,\n","      \"conv_clamp\": 256\n","    }\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"channel_base\": 16384,\n","    \"channel_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 0.8192\n","  },\n","  \"total_kimg\": 25000,\n","  \"batch_size\": 16,\n","  \"batch_gpu\": 16,\n","  \"ema_kimg\": 5.0,\n","  \"ema_rampup\": 0.05,\n","  \"ada_target\": 0.6,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"run_dir\": \"/content/drive/My Drive/Colab Notebooks/Health/torch_res_b256/00000-torch_data_benign_256-auto1\"\n","}\n","\n","Output directory:   /content/drive/My Drive/Colab Notebooks/Health/torch_res_b256/00000-torch_data_benign_256-auto1\n","Training data:      /content/drive/My Drive/Colab Notebooks/Health/torch_data_benign_256\n","Training duration:  25000 kimg\n","Number of GPUs:     1\n","Number of images:   437\n","Image resolution:   256\n","Conditional model:  False\n","Dataset x-flips:    False\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","Num images:  437\n","Image shape: [1, 256, 256]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Generator             Parameters  Buffers  Output shape         Datatype\n","---                   ---         ---      ---                  ---     \n","mapping.fc0           262656      -        [16, 512]            float32 \n","mapping.fc1           262656      -        [16, 512]            float32 \n","mapping               -           512      [16, 14, 512]        float32 \n","synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n","synthesis.b4.torgb    263169      -        [16, 1, 4, 4]        float32 \n","synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n","synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n","synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n","synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n","synthesis.b8.torgb    263169      -        [16, 1, 8, 8]        float32 \n","synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n","synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n","synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n","synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n","synthesis.b16.torgb   263169      -        [16, 1, 16, 16]      float32 \n","synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n","synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n","synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n","synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n","synthesis.b32.torgb   263169      -        [16, 1, 32, 32]      float16 \n","synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n","synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n","synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n","synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n","synthesis.b64.torgb   131585      -        [16, 1, 64, 64]      float16 \n","synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n","synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n","synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n","synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n","synthesis.b128.torgb  65793       -        [16, 1, 128, 128]    float16 \n","synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n","synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n","synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n","synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n","synthesis.b256.torgb  32897       -        [16, 1, 256, 256]    float16 \n","synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n","synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n","---                   ---         ---      ---                  ---     \n","Total                 23186516    175568   -                    -       \n","\n","\n","Discriminator  Parameters  Buffers  Output shape         Datatype\n","---            ---         ---      ---                  ---     \n","b256.fromrgb   128         16       [16, 64, 256, 256]   float16 \n","b256.skip      8192        16       [16, 128, 128, 128]  float16 \n","b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n","b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n","b256           -           16       [16, 128, 128, 128]  float16 \n","b128.skip      32768       16       [16, 256, 64, 64]    float16 \n","b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n","b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n","b128           -           16       [16, 256, 64, 64]    float16 \n","b64.skip       131072      16       [16, 512, 32, 32]    float16 \n","b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n","b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n","b64            -           16       [16, 512, 32, 32]    float16 \n","b32.skip       262144      16       [16, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n","b32            -           16       [16, 512, 16, 16]    float16 \n","b16.skip       262144      16       [16, 512, 8, 8]      float32 \n","b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n","b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n","b16            -           16       [16, 512, 8, 8]      float32 \n","b8.skip        262144      16       [16, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n","b8             -           16       [16, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [16, 512]            float32 \n","b4.out         513         -        [16, 1]              float32 \n","---            ---         ---      ---                  ---     \n","Total          24000961    416      -                    -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 1m 16s       sec/tick 11.1    sec/kimg 694.60  maintenance 64.5   cpumem 3.98   gpumem 11.15  augment 0.000\n","Evaluating metrics...\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","{\"results\": {\"fid50k_full\": 404.9091763536917}, \"metric\": \"fid50k_full\", \"total_time\": 630.9810593128204, \"total_time_str\": \"10m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1653580593.0423868}\n","tick 1     kimg 4.0      time 16m 28s      sec/tick 276.4   sec/kimg 69.11   maintenance 636.5  cpumem 4.93   gpumem 9.38   augment 0.000\n","tick 2     kimg 8.0      time 21m 06s      sec/tick 277.2   sec/kimg 69.31   maintenance 0.1    cpumem 4.93   gpumem 4.76   augment 0.000\n","tick 3     kimg 12.0     time 25m 43s      sec/tick 277.1   sec/kimg 69.27   maintenance 0.1    cpumem 4.93   gpumem 4.77   augment 0.000\n","tick 4     kimg 16.0     time 30m 21s      sec/tick 278.2   sec/kimg 69.55   maintenance 0.1    cpumem 4.93   gpumem 4.77   augment 0.000\n","tick 5     kimg 20.0     time 34m 59s      sec/tick 277.9   sec/kimg 69.47   maintenance 0.1    cpumem 4.93   gpumem 4.76   augment 0.001\n","tick 6     kimg 24.0     time 39m 38s      sec/tick 277.9   sec/kimg 69.47   maintenance 0.1    cpumem 4.93   gpumem 4.77   augment 0.004\n","tick 7     kimg 28.0     time 44m 16s      sec/tick 278.2   sec/kimg 69.54   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.008\n","tick 8     kimg 32.0     time 48m 54s      sec/tick 278.3   sec/kimg 69.56   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.012\n","tick 9     kimg 36.0     time 53m 32s      sec/tick 277.5   sec/kimg 69.38   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.017\n","tick 10    kimg 40.0     time 58m 11s      sec/tick 278.6   sec/kimg 69.65   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.022\n","Evaluating metrics...\n","{\"results\": {\"fid50k_full\": 154.62740500079192}, \"metric\": \"fid50k_full\", \"total_time\": 626.2752044200897, \"total_time_str\": \"10m 26s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1653584006.3692827}\n","tick 11    kimg 44.0     time 1h 13m 23s   sec/tick 277.9   sec/kimg 69.48   maintenance 634.8  cpumem 4.93   gpumem 4.78   augment 0.027\n","tick 12    kimg 48.0     time 1h 18m 02s   sec/tick 278.8   sec/kimg 69.71   maintenance 0.1    cpumem 4.93   gpumem 4.81   augment 0.031\n","tick 13    kimg 52.0     time 1h 22m 40s   sec/tick 278.1   sec/kimg 69.51   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.037\n","tick 14    kimg 56.0     time 1h 27m 18s   sec/tick 277.7   sec/kimg 69.42   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.044\n","tick 15    kimg 60.0     time 1h 31m 56s   sec/tick 277.9   sec/kimg 69.48   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.049\n","tick 16    kimg 64.0     time 1h 36m 35s   sec/tick 278.2   sec/kimg 69.56   maintenance 0.1    cpumem 4.93   gpumem 4.80   augment 0.054\n","tick 17    kimg 68.0     time 1h 41m 12s   sec/tick 277.5   sec/kimg 69.38   maintenance 0.2    cpumem 4.93   gpumem 4.80   augment 0.057\n","tick 18    kimg 72.0     time 1h 45m 51s   sec/tick 278.5   sec/kimg 69.63   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.061\n","tick 19    kimg 76.0     time 1h 50m 29s   sec/tick 277.7   sec/kimg 69.41   maintenance 0.1    cpumem 4.93   gpumem 4.78   augment 0.065\n","tick 20    kimg 80.0     time 1h 55m 07s   sec/tick 278.4   sec/kimg 69.61   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.068\n","Evaluating metrics...\n","{\"results\": {\"fid50k_full\": 144.25274749803484}, \"metric\": \"fid50k_full\", \"total_time\": 624.8489980697632, \"total_time_str\": \"10m 25s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1653587422.0908244}\n","tick 21    kimg 84.0     time 2h 10m 19s   sec/tick 278.2   sec/kimg 69.55   maintenance 633.6  cpumem 4.93   gpumem 4.80   augment 0.074\n","tick 22    kimg 88.0     time 2h 14m 57s   sec/tick 277.7   sec/kimg 69.42   maintenance 0.1    cpumem 4.93   gpumem 4.80   augment 0.077\n","tick 23    kimg 92.0     time 2h 19m 35s   sec/tick 277.9   sec/kimg 69.49   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.080\n","tick 24    kimg 96.0     time 2h 24m 14s   sec/tick 278.3   sec/kimg 69.58   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.084\n","tick 25    kimg 100.0    time 2h 28m 51s   sec/tick 277.4   sec/kimg 69.36   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.087\n","tick 26    kimg 104.0    time 2h 33m 30s   sec/tick 278.4   sec/kimg 69.60   maintenance 0.1    cpumem 4.93   gpumem 4.80   augment 0.090\n","tick 27    kimg 108.0    time 2h 38m 08s   sec/tick 277.5   sec/kimg 69.38   maintenance 0.1    cpumem 4.93   gpumem 4.79   augment 0.093\n","tick 28    kimg 112.0    time 2h 42m 46s   sec/tick 278.3   sec/kimg 69.58   maintenance 0.1    cpumem 4.93   gpumem 4.80   augment 0.096\n","tick 29    kimg 116.0    time 2h 47m 24s   sec/tick 277.9   sec/kimg 69.46   maintenance 0.1    cpumem 4.93   gpumem 4.81   augment 0.100\n","tick 30    kimg 120.0    time 2h 52m 02s   sec/tick 278.1   sec/kimg 69.52   maintenance 0.1    cpumem 4.93   gpumem 4.81   augment 0.103\n","Evaluating metrics...\n","{\"results\": {\"fid50k_full\": 142.65140456910615}, \"metric\": \"fid50k_full\", \"total_time\": 623.4980478286743, \"total_time_str\": \"10m 23s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1653590835.6546357}\n","tick 31    kimg 124.0    time 3h 07m 13s   sec/tick 278.2   sec/kimg 69.56   maintenance 632.4  cpumem 4.98   gpumem 4.79   augment 0.104\n","tick 32    kimg 128.0    time 3h 11m 51s   sec/tick 278.2   sec/kimg 69.56   maintenance 0.1    cpumem 4.98   gpumem 4.80   augment 0.107\n","tick 33    kimg 132.0    time 3h 16m 29s   sec/tick 277.5   sec/kimg 69.38   maintenance 0.2    cpumem 4.98   gpumem 4.80   augment 0.109\n","tick 34    kimg 136.0    time 3h 21m 07s   sec/tick 278.2   sec/kimg 69.55   maintenance 0.1    cpumem 4.98   gpumem 4.79   augment 0.111\n","tick 35    kimg 140.0    time 3h 25m 45s   sec/tick 277.6   sec/kimg 69.41   maintenance 0.1    cpumem 4.98   gpumem 4.80   augment 0.112\n","tick 36    kimg 144.0    time 3h 30m 23s   sec/tick 278.3   sec/kimg 69.57   maintenance 0.1    cpumem 4.98   gpumem 4.80   augment 0.114\n","tick 37    kimg 148.0    time 3h 35m 01s   sec/tick 277.6   sec/kimg 69.41   maintenance 0.1    cpumem 4.98   gpumem 4.79   augment 0.116\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"StyleGAN2_train_benign_256.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/present/blob/master/youtube/gan/colab_gan_train.ipynb","timestamp":1651846327304}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}